<!-- This file needs to be edited by the lab developer to suit
the requirements of their lab in particular.-->

<!-- Add class="default" to include any element as it is
specified in default.html. 
Do not include class="default" to the elements that you want to
edit -->

<!DOCTYPE html>
<html>
<head></head>
<body>

<div id="experiment"> <!-- The Experiment Document Container-->

  <!-- The lab Header contains the logo and the name of the lab,
  usually displayed on the top of the page-->

  <header id="experiment-header" class="default">
  
    <div id="experiment-header-logo" class="logo">
      <!-- Enclose the logo image of your lab or write it in 
      text-->
      <img src="../images/logo.jpg" />
    </div>

    <div id="experiment-header-heading" class="heading">
      <!-- Write the name of your lab and link it to the home 
      page of your lab (h1 tag is preferred while writing your 
      lab name)-->
      <a href="../index.php">PR Virtual Lab</a>	
    </div>

    <!-- Add any additional element you want to add to the lab 
    header, For example : Help (Enclosing them with suitable 
    div is recommended)-->

  </header>


  <!-- The lab article is the main content area where all the 
  experiment content sits-->
  <article id="experiment-article">
  
    <!-- The lab article has an header, optional navigational 
    menu, number of sections, an optional sidebar and a closing 
    footer-->
     <div id="experiment-article-breadcrumb" class="breadcrumb">
     </div>
    
      <header id="experiment-article-heading" class="heading">
        <!-- You can add a welcome message or title of the 
        experiment here -->
	Bayesian Classification
        <!-- Add any additional element if required with proper 
        enclosing-->
      </header>

      <!-- Navigation menu is useful to organize the view of 
      multiple sections inside the article-->
      <nav id="experiment-article-navigation" class="default">
        <ul id="experiment-article-navigation-menu">
          <!-- The menu can be dynamically generated to contain 
          the headings of your sections or instead write the 
          menu items of your choice individually enclosedu in 
          <li> tag as shown below-->
        </ul>
      </nav>

      <!-- All the sections of your lab or experiment can be 
      enclosed together with a div element as shown below-->
      <div id="experiment-article-sections">

        <!-- First section of the article-->
        <section id="experiment-article-section-1">
          
          <div id="experiment-article-section-1-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab -->
	    <img src="../images/introduction.jpg" />
	  </div>	
          
          <!-- The heading for the section can be enclosed in a 
          div tag. -->
          <div id="experiment-article-section-1-heading" 
          class="heading">
            Introduction
          </div>

          <!-- Write the section content inside a paragraph 
          element, You can also include images with <img> tag -->
	  <div id="experiment-article-section-1-content" 
	     class="content">	
	     <p> Linear perceptrons allow us to learn a decision boundary that would separate
	     two classes. They are very effective when there are only two classes, and they are
	     well separated. Such classifiers are referred to as discriminative classifiers.</p>
	     <p> In contrast, generative classifiers consider each sample as a random vector, and
	     explicity model each class by their distribution or density functions. To carry out
	     the classification, we compute the likelihood that a given sample belong to each of the
	     candidate classes, and assign the sample to the class that is most likely. In other words,
	     we need to compute P(&#969<sub>i</sub>/x) for each class &#969<sub>i</sub>. However, the
	     density functions provide only the likelihood of seeing a particular sample, given that
	     the sample belongs to a specific class. i.e., the density functions provide us p(x/&#969<sub>i</sub>).
	     The Bayes rule provides us with an approach to compute the likelihood of the class for
	     a given sample, from the density functions and related information.
	  </div>
	  </section>

	  <!-- Second section of the article-->
	  <section id="experiment-article-section-2">
	  <div id="experiment-article-section-2-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab. -->
	     <img src="../images/theory.jpg" />
	  </div>

	  <!-- The heading for the section can be enclosed in a 
	  div tag. -->
	  <div id="experiment-article-section-2-heading" 
	     class="heading">
	     Theory
	  </div>

	  <!-- Write the section content inside a paragraph 
	  element, we can also include images with <img> tag -->
	  <div id="experiment-article-section-2-content" 
	     class="content">

	     <p>Consider the following quote from a 2000 article in the Economist on the Bayesian Approach
	     [<a href="http://www.ai.mit.edu/%7emurphyk/Bayes/economist.html">link</a><span style="color: rgb(0, 0, 0);">]:</span>
	     </p>
	     <p><i>"The essence of the Bayesian approach is to provide a mathematical rule explaining 
		how you should change your existing beliefs in the light of new evidence. In
		other words, it allows us to combine new data with their existing knowledge or
		expertise. The canonical example is to imagine that a precocious newborn observes 
		his first sunset, and wonders whether the sun will rise again or not. He assigns 
		equal prior probabilities to both possible outcomes, and represents this by placing
		one white and one black marble into a bag. The following day, when
		the sun rises, the child places another white marble in the bag. The
		probability that a marble plucked randomly from the bag will be white (i.e., the 
		child's degree of belief in future sunrises) has thus gone from a half to two-thirds. 
		After sunrise the next day, the child adds another white marble, and the probability 
		(and thus the degree of belief) goes from two-thirds to three-quarters. And so on. 
		Gradually, the initial belief that the sun is just as likely as not to rise each
		morning is modified to become a near-certainty that the sun will always
		rise." </i></p>

	     <span style="font-size: 10pt;"><span style="font-family: 'Times New Roman',serif;"></span></span>
	     <p><span style="color: rgb(0, 0, 0);"><span>&nbsp;</span></span></p>

	     <p> In terms of classification, the Bayes theorem allows us to combine prior probabilities,
	     along with observed evidence to arrive at the posterior probability. More or less, conditional
	     probabilities represent the probability of an event occurring given evidence. To better
	     understand, Bayes Theorem can be derived from the joint probability of
	     A and B (i.e. <i>P</i>(<i>A,B</i>)) as
	     follows:</span></p>
	  <br>
	  <p style="text-align: center;"><span style="color: rgb(0, 0, 0);"> <span class="WPCharBoxWrapper" style="width: 217px;"><span class="WPCharBox" style="border: medium none ;"><img src="images/ole.gif" alt="ole.gif" border="0" height="101" width="217"></span></span> </span></p>
	  <br>

	  <p><span style="color: rgb(0, 0, 0);">where
	     </span><span class="serifequation"><span style="color: rgb(0, 0, 0);"><i><span style="font-weight: bold;">P</span></i><span style="font-weight: bold;">(<i>A</i>|<i>B</i>)</span></span></span><span style="color: rgb(0, 0, 0);"> is referred to as the <i>posterior</i>;
	     <i><span style="font-weight: bold;">P</span></i><span style="font-weight: bold;">(<i>B</i>|<i>A</i>)</span>
	     is known as the <i>likelihood</i>, <i><span style="font-weight: bold;">P</span></i><span style="font-weight: bold;">(<i>A</i>)</span>
	     is the <i>prior</i>
	     and <i><span style="font-weight: bold;">P</span></i><span style="font-weight: bold;">(<i>B</i>)</span>
	     is generally the <i>evidence</i> and is used as a scaling factor. Therefore, it is handy to
	     remember Bayes Rule as:</span></p>

	  <p style="text-align: center;"><span style="color: rgb(0, 0, 0);"> <span class="WPCharBoxWrapper" style="width: 237px;"><span class="WPCharBox" style="border: medium none ;"><img src="images/ole1.gif" alt="ole1.gif" border="0" height="47" width="237"></span></span> </span></p>

	  <p><span style="color: rgb(0, 0, 0);">&nbsp;These terms will be discussed a little later.</span></p>
       </div>
       </section>

       <section id="experiment-article-section-3">
       <div id="experiment-article-section-3-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab. -->
	     <img src="../images/objective.jpg" />
	  </div>

	  <div id="experiment-article-section-3-heading" 
	     class="heading">
	     Objective
	  </div>

	  <div id="experiment-article-section-3-content" 
	     class="content">
	     <p>The high level goals of the experiment are:
	     <ol>
		<li>  To understand the computation of likelihood of a class, given a sample.</li>
		<li>  To understand the the use of density/distribution functions to model a class.</li>
		<li>  To understand the effect of prior probabilities in Bayesian classification.</li>
		<li>  To understand how two (or more) density functions interact in the feature space to
		decide a decision boundary between classes.</li>
		<li>  To understand how the decision boundary varies based on nature of the density functions.</li>
	     </ol>
	     </p>
	  </div>
	  </section>

	  <section id="experiment-article-section-4">
	  <div id="experiment-article-section-4-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab.-->
	     <img src="../images/simulation.jpg" />
	  </div>

	  <div id="experiment-article-section-4-heading" 
	     class="heading">
	     Experiment
	  </div>

	  <div id="experiment-article-section-4-content" 
	     class="content">
		<p><a href="../docs/java-and-icedtea-plugin.pdf">Install prerequisites to run the simulation</a></p>
	     <p>
             <a href="../experiment/compressed_files/5/Exp5.tar.gz">   Click here to open the Experiment for Linux systems</a>
             </p>
             <p>
             <a href="../experiment/compressed_files/5/Exp5.zip">   Click here to open the Experiment for Windows</a>
	     </p>
	  </div>

	  </section>

	  <!--
	  <section id="experiment-article-section-5">

	  <div id="experiment-article-section-5-icon" 
	     class="icon">
	     <img src="../images/manual.jpg" />
	  </div>

	  <div id="experiment-article-section-5-heading" 
	     class="heading">
	     Manual
	  </div>

	  <div id="experiment-article-section-5-content" 
	     class="content">

	  </div>

	  </section>
	  -->

	  <section id="experiment-article-section-6">

	  <div id="experiment-article-section-6-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab.-->
	     <img src="../images/quizzes.jpg" />
	  </div>

	  <div id="experiment-article-section-6-heading" 
	     class="heading">
	     Quizzes
	  </div>

	  <div id="experiment-article-section-6-content" 
	     class="content">
	     <p>
	     <b>Q1.</b> The covariance matrix is always
	     <br/><br/>
	     a. Square<br/>
	     b. Positive Semidefinite<br/>
	     c. Positive Definite<br/>
	     d. Symmetric <br/>
	     e. None of the above. <br/>
	     <br/><br/>
	     For each of the properties you selected, describe what would happen if the covariance
	     matrix does not satisfy that property.
	     <br/><br/>
	     <b>Q2.</b> Describe the possible set of decision boundaries that can be generated using
	     gaussian density functions in a two class problem.
	     <br/><br/>
	     <!-- <input type="submit" value="Submit Answers"> -->
	     </p>

	  </div>

	  </section>

	  <section id="experiment-article-section-7">

	  <div id="experiment-article-section-7-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab. -->
	     <img src="../images/procedure.jpg" />
	  </div>

	  <div id="experiment-article-section-7-heading" 
	     class="heading">
	     Procedure
	  </div>

	  <div id="experiment-article-section-7-content" 
	     class="content">
	     <h3>Stage 1:</h3>
	     <ol>
		<li> Lauch the experiment and clear the pane. Assign differnt means and covariances for each
		of the classes and observe the resulting densities. Use the mark-all button to observe the
		decision boundaries.</li>
		<li> Note down your observations on the relationship between the decision boundaries and the
		density functions.</li>
	     </ol>

	     <h3>Stage 2:</h3>
	     <ol>
		<li> Repeat the above procedure for different values of prior probabilities.</li>
		<li> Observe the change in the scaled density functions and decision boundaries</li>
		<li> Note down your observations regarding the change of decision boundaries</li>
	     </ol>

	     <h3>Stage 3:</h3>
	     <p>Generate the following types of decision boundaries by varying the means and covariance matrices.
	     <ol>
		<li> Straight line </li>
		<li> Parallel Straight lines </li>
		<li> Concentric circles </li>
		<li> Parabola </li>
		<li> Hyperbola </li>
		<li> Four Quadrants </li>
	     </ol>
	     </p>
	     <p>Explain why these shapes are generated in each case.</p>
	  </div>
	  </section>

	  <section id="experiment-article-section-8">
	  <div id="experiment-article-section-8-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab.-->
	     <img src="../images/readings.jpg" />
	  </div>

	  <div id="experiment-article-section-8-heading" 
	     class="heading">
	     Further Readings
	  </div>

	  <div id="experiment-article-section-8-content" 
	     class="content">
	     <ul>
		<li> <a href="http://www.rii.ricoh.com/~stork/DHS.html">Pattern Classification</a>,
		by  Duda, Hart and Stork (ed). Second Edition, Wiley, 2001.
		</li>
		<li> Article on <a href="http://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes Theorem</a> at Wikipedia.
		</li>
		<li> Article on <a href="http://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naive Bayes Classifier</a> at Wikipedia.
		</li>
	     </ul>

	  </div>

	  </section>

       </div>


       <!-- An article can have a sidebar that contain related 
       links and additional material (however it is kept optional 
       at this moment) -->
       <aside id="lab-article-sidebar" class="default">
       <!-- put the content that you want to appear in the 
       sidebar -->	
       </aside>


       <!-- Article footer can display related content and 
       additional links -->						
       <footer id="lab-article-footer" class="default">
       <!-- Put the content that you want to appear here -->
       </footer>

       </article>


       <!-- Links to other labs, about us page can be kept the lab 
       footer-->
       <footer id="lab-footer" class="footer">
       <!-- Put the content here-->
       <a href="http://virtual-labs.ac.in/nmeict" >Sponsored by MHRD (NME-ICT) </a> | <a
	  href="http://virtual-labs.ac.in/licensing" target="_blank"> Licensing Terms </a>
       </footer>
    </div>		

 </body>
</html>
