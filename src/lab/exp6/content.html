<!-- This file needs to be edited by the lab developer to suit
the requirements of their lab in particular.-->

<!-- Add class="default" to include any element as it is
specified in default.html. 
Do not include class="default" to the elements that you want to
edit -->

<!DOCTYPE html>
<html>
<head></head>
<body>

<div id="experiment"> <!-- The Experiment Document Container-->

  <!-- The lab Header contains the logo and the name of the lab,
  usually displayed on the top of the page-->

  <header id="experiment-header" class="default">
  
    <div id="experiment-header-logo" class="logo">
      <!-- Enclose the logo image of your lab or write it in 
      text-->
      <img src="../images/logo.jpg" />
    </div>

    <div id="experiment-header-heading" class="heading">
      <!-- Write the name of your lab and link it to the home 
      page of your lab (h1 tag is preferred while writing your 
      lab name)-->
      <a href="../index.php">PR Virtual Lab</a>	
    </div>

    <!-- Add any additional element you want to add to the lab 
    header, For example : Help (Enclosing them with suitable 
    div is recommended)-->
  </header>

  <!-- The lab article is the main content area where all the 
  experiment content sits-->
  <article id="experiment-article">
  
    <!-- The lab article has an header, optional navigational 
    menu, number of sections, an optional sidebar and a closing 
    footer-->
     <div id="experiment-article-breadcrumb" class="breadcrumb">
     </div>
    
      <header id="experiment-article-heading" class="heading">
        <!-- You can add a welcome message or title of the 
        experiment here -->
	MLE: Learning the Classifier from Data
        <!-- Add any additional element if required with proper 
        enclosing-->
      </header>

      <!-- Navigation menu is useful to organize the view of 
      multiple sections inside the article-->
      <nav id="experiment-article-navigation" class="default">
        <ul id="experiment-article-navigation-menu">
          <!-- The menu can be dynamically generated to contain 
          the headings of your sections or instead write the 
          menu items of your choice individually enclosedu in 
          <li> tag as shown below-->
        </ul>
      </nav>

      <!-- All the sections of your lab or experiment can be 
      enclosed together with a div element as shown below-->
      <div id="experiment-article-sections">

        <!-- First section of the article-->
        <section id="experiment-article-section-1">
          
          <div id="experiment-article-section-1-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab -->
	    <img src="../images/introduction.jpg" />
	  </div>	
          
          <!-- The heading for the section can be enclosed in a 
          div tag. -->
          <div id="experiment-article-section-1-heading" 
          class="heading">
            Introduction
          </div>

          <!-- Write the section content inside a paragraph 
          element, You can also include images with <img> tag -->
	  <div id="experiment-article-section-1-content" 
	     class="content">	
	     <p> In the previous experiment, we learned about how to generate a classifier, given
	     models for each of the classes, using the Bayes Rule. The next goal is to learn such
	     a classifier, automatically, given a set of labelled samples from each of the possible
	     classes.</p>
	     <p> Before doing this experiment, you should ensure that you have understood the previous
	     experiment on Bayesian Classification as well as the experiment on Mean and Covariance
	     estimateion from Data.</p>
	     <p>The idea behind maximum likelihood parameter estimation is to determine the parameters 
	     that maximize the probability (likelihood) of the sample data. From a statistical point 
	     of view, the method of maximum likelihood is considered to be more robust (with some 
	     exceptions) and yields estimators with good statistical properties. In other words, MLE 
	     methods are versatile and apply to most models and to different types of data. In addition, 
	     they provide efficient methods for quantifying uncertainty through confidence bounds. 
	     Although the methodology for maximum likelihood estimation is simple, the implementation 
	     is mathematically intense. Using today's computer power, however, mathematical complexity
	     is not a big obstacle.
	     </p>
	     <p>
	     The MLE is an important type of estimator for the following reasons:
	     <ol>
		<li>  The MLE implements the likelihood principle.</li>
		<li>  MLEs are often simple and easy to compute. </li>
		<li>  MLEs have asymptotic optimality properties
		(consistency and efficiency). </li>
		<li>  MLEs are invariant under reparameterization. </li>
		<li>  If an efficient estimator exists, it is the MLE. </li>
		<li>  In signal detection with unknown parameters 
		(composite hypothesis testing), MLEs are used in implementing the 
		generalized likelihood ratio test (GLRT).</li>
	     </ol>
	     </p>
	  </div>


	  </section>

	  <!-- Second section of the article-->
	  <section id="experiment-article-section-2">

	  <div id="experiment-article-section-2-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab. -->
	     <img src="../images/theory.jpg" />
	  </div>

	  <!-- The heading for the section can be enclosed in a 
	  div tag. -->
	  <div id="experiment-article-section-2-heading" 
	     class="heading">
	     Theory
	  </div>


	  <!-- Write the section content inside a paragraph 
	  element, we can also include images with <img> tag -->
	  <div id="experiment-article-section-2-content" 
	     class="content">
	     <p> As learned from the previous experiment, if we have a generative model for each of
	     the classes, one can devlop a classifier that assigns an unknown sample to one of the
	     possible set of classes. </p>
	     <p>
	     Suppose there is a sample x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub> of <i>n</i> iid observations, coming from a distribution 
	     with an unknown pdf ƒ<sub>0</sub>(·). It is however surmised that the function ƒ<sub>0</sub> belongs to a 
	     certain family of distributions { ƒ(·|&theta;), &theta; &isin; &Theta; }, called the parametric model, so 
	     that ƒ<sub>0</sub> = ƒ(·|&theta;<sub>0</sub>). The value &theta;<sub>0</sub> is unknown and is referred to as the "true value" 
	     of the parameter. It is desirable to find some estimator <img src="images/thetahat.png"> which
	     would be as close to the true value &theta;<sub>0</sub> as possible. Both the observed variables x<sub>0</sub> 
	     and the parameter θ can be vectors.
	     </p>
	     <p>
	     To use the method of maximum likelihood, one first specifies the joint density function for all the the observations. For an Independent and Identically distributed distribution, this joint density function will be <br />
	     <img src="images/jointdistributionfunction.png"> 
	     </p>
	     <p>
	     Now we look at this function from a different perspective by considering the observed values x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub> to be fixed “parameters” of this function, whereas &theta; will be the function’s variable and allowed to vary freely. From this point of view this distribution function will be called the likelihood: 
	     </br>
	     <img src="images/likelihoodfunction.png">
	     </br>
	     </p>
	     <p>
	     In practice it is often more convenient to work with the logarithm of the likelihood function, called the log-likelihood, or its scaled version, called the average log-likelihood:</ br>
	     <img src="images/loglikelihood.png">
	     </p>
	     <p>
	     The method of maximum likelihood estimates &theta;<sub>0</sub> by finding a value of θ that maximizes <img src="images/lhat.png">. This method of estimation is a maximum likelihood estimator (MLE) of &theta;<sub>0</sub>:
	     <img src="images/mletheta.png">
	     </p>
	     <p>
	     A MLE estimate is the same regardless of whether we maximize the likelihood or the log-likelihood function, since log is a monotone transformation. 

	     For many models, a maximum likelihood estimator can be found as an explicit function of the observed data x<sub>1</sub>,..., x<sub>n</sub>. For many other models, however, no closed-form solution to the maximization problem is known or available, and a MLE has to be found numerically using optimization methods. For some problems, there may be multiple estimates that maximize the likelihood. For other problems, no maximum likelihood estimate exists (meaning that the log-likelihood function increases without attaining the supremum value).
	     </p>
	     <p>
	     A maximum likelihood estimator coincides with the most probable Bayesian estimator given a uniform prior distribution on the parameters.
	     </p>
	    

	     <p><b>Example for a Normal Distribution, Bernoulli distribution and Poisson distribution:<b></p>
	     <!--	&#402;(x<sub>1</sub>,......,x<sub>n</sub>)=&Pi;e<sup>-(x-&mu;)<sup>2</sup>/(2&sigma;<sup>2</sup>)</sup>
	     =(2&pi;)<sup>-n/2</sup> -->
	     <p>See the page <a href="http://mathworld.wolfram.com/MaximumLikelihood.html" target="_blank">http://mathworld.wolfram.com/MaximumLikelihood.html</a></p>
	  </div>
	  </section>


	  <section id="experiment-article-section-3">
	  <div id="experiment-article-section-3-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab. -->
	     <img src="../images/objective.jpg" />
	  </div>

	  <div id="experiment-article-section-3-heading" 
	     class="heading">
	     Objective
	  </div>

	  <div id="experiment-article-section-3-content" 
	     class="content">
	     <p>The high level goals of the experiment are:
	     <ol>
		<li> To understand the modelling of a class in terms of density functions and priors.</li>
		<li> To understand the estimation of the parameters of a model from a set of samples.</li>
		<li> To understand the effect of sample size on decision boundary.</li>
	     </ol>
	     </p>

	  </div>

	  </section>


	  <section id="experiment-article-section-4">

	  <div id="experiment-article-section-4-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab.-->
	     <img src="../images/simulation.jpg" />
	  </div>

	  <div id="experiment-article-section-4-heading" 
	     class="heading">
	     Experiment
	  </div>

	  <div id="experiment-article-section-4-content" 
	     class="content">
		<p><a href="../docs/java-and-icedtea-plugin.pdf">Install prerequisites to run the simulation</a></p>
	     <p>
             <a href="../experiment/compressed_files/6/Exp6.tar.gz">   Click here to open the Experiment for Linux systems</a>
             </p>
             <p>
             <a href="../experiment/compressed_files/6/Exp6.zip">   Click here to open the Experiment for Windows</a>
	     </p>
	  </div>

	  </section>

	  <!--
	  <section id="experiment-article-section-5">

	  <div id="experiment-article-section-5-icon" 
	     class="icon">
	     <img src="../images/manual.jpg" />
	  </div>

	  <div id="experiment-article-section-5-heading" 
	     class="heading">
	     Manual
	  </div>

	  <div id="experiment-article-section-5-content" 
	     class="content">

	  </div>

	  </section>
	  -->
	  <section id="experiment-article-section-6">

	  <div id="experiment-article-section-6-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab.-->
	     <img src="../images/quizzes.jpg" />
	  </div>

	  <div id="experiment-article-section-6-heading" 
	     class="heading">
	     Quizzes
	  </div>

	  <div id="experiment-article-section-6-content" 
	     class="content">
	     <p> Answer the questions provided at the end of the writeup <a href="../exp5/RandomVariables.pdf">HERE</a>.
	     Some of the questions require you to do minimal amount of programming. You are encouraged to
	     try out variants of the goals mentioned in the programming questions.
	     </p>

	  </div>

	  </section>

	  <section id="experiment-article-section-7">

	  <div id="experiment-article-section-7-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab. -->
	     <img src="../images/procedure.jpg" />
	  </div>

	  <div id="experiment-article-section-7-heading" 
	     class="heading">
	     Procedure
	  </div>

	  <div id="experiment-article-section-7-content" 
	     class="content">
	     <p> In the experiment window,</p>
	     <ol>
		<li> Select the distribution function using the drop-down menu at top right .</li>
		<li> Plot the datasets and see the distribution </li>
		<li> Estimate the maximum likelihood parameters </li>
		<li> Use Mark all Button to see the classifier </li>
	     </ol>
	  </div>

	  </section>


	  <section id="experiment-article-section-8">

	  <div id="experiment-article-section-8-icon" 
	     class="icon">
	     <!-- Enclose the icon image of your lab.-->
	     <img src="../images/readings.jpg" />
	  </div>

	  <div id="experiment-article-section-8-heading" 
	     class="heading">
	     Further Readings
	  </div>

	  <div id="experiment-article-section-8-content" 
	     class="content">
	     <p>
	   <ul>
	     <li> <a href="http://www.rii.ricoh.com/~stork/DHS.html">Pattern Classification</a>,
	     by  Duda, Hart and Stork (ed). Second Edition, Wiley, 2001.
	     </li>
	     <li> Article on <a href="http://en.wikipedia.org/wiki/Random_number_generation">Random Number Generation</a> at Wikipedia.
	     </li>
	     <li> Article on <a href="http://en.wikipedia.org/wiki/Pseudorandom_number_generator">Pseudorandom Number Generators</a> at Wikipedia.
	     </li>
	  </ul>
	</p>
       </div>

       </section>

    </div>


    <!-- An article can have a sidebar that contain related 
    links and additional material (however it is kept optional 
    at this moment) -->
    <aside id="lab-article-sidebar" class="default">
    <!-- put the content that you want to appear in the 
    sidebar -->	
    </aside>


    <!-- Article footer can display related content and 
    additional links -->						
    <footer id="lab-article-footer" class="default">
    <!-- Put the content that you want to appear here -->
    </footer>

    </article>


    <!-- Links to other labs, about us page can be kept the lab 
    footer-->
    <footer id="lab-footer" class="footer">
    <!-- Put the content here-->
    <a href="http://virtual-labs.ac.in/nmeict" >Sponsored by MHRD (NME-ICT) </a> | <a
       href="http://virtual-labs.ac.in/licensing" target="_blank"> Licensing Terms </a>
    </footer>
 </div>		

 </body>
</html>
